# -*- coding: utf-8 -*-
"""Song_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BZqzz-M2JfvNrSPAgCtHQhSM6xbhSPGn
"""

# Commented out IPython magic to ensure Python compatibility.
# To support both python 2 and python 3
from __future__ import division, print_function, unicode_literals
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
from sklearn import preprocessing
import warnings
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl

import numpy as np
import os
import pandas as pd
# To make this notebook's output stable across runs
np.random.seed(42)

# To plot pretty figures
# %matplotlib inline
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# set style of plots
sns.set_style('white')

# define a custom palette
customPalette = ['#630C8C', '#39C1C6', '#Dd526C', '#Fcc139']
sns.set_palette(customPalette)
sns.palplot(customPalette)


# Ignore useless warnings (see SciPy issue #5998)
warnings.filterwarnings(action="ignore", message="^internal gelsd")

# Import my spotify data
songs = pd.read_csv("moods1.csv")

songs.info()

songs = songs.drop(['tempo', 'time_signature', 'key', 'length',
                    'popularity', 'mood', 'album', 'release_date'], axis=1)
songs.head()

# to describe numerical features we can use describe()
songs.describe()

# Loudness feature is from -60db to 0 so we will normalise this column between 0 and 1
# Tempo feature is in BPM so we will scale between 0 and 1 too

loudness = songs[['loudness']].values
min_max_scaler = preprocessing.MinMaxScaler()
loudness_scaled = min_max_scaler.fit_transform(loudness)
songs['loudness'] = pd.DataFrame(loudness_scaled)


songs.hist(bins=50, figsize=(20, 15))

"""Most features are skewed to the left or the right

"""

# from pandas.plotting import scatter_matrix
# # attributes should contain the features we want to compare
# attr = ['danceability','energy','loudness','speechiness','acousticness','tempo','liveness','valence']

# scatter_matrix(songs[attr],figsize=(12,8))

# remove song names, artist and id before clustering
songs_features = songs.copy()
songs_features = songs_features.drop(
    ['name', 'artist', 'id', 'liveness', 'speechiness', 'instrumentalness'], axis=1)

songs_features


Sum_of_squared_distances = []
K = range(1, 15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(songs_features)
    Sum_of_squared_distances.append(km.inertia_)

for n_clusters in range(2, 15):
    clusterer = KMeans(n_clusters=n_clusters)
    preds = clusterer.fit_predict(songs_features)
    centers = clusterer.cluster_centers_

    score = silhouette_score(songs_features, preds, metric='euclidean')
    print("For n_clusters = {}, silhouette score is {})".format(
        n_clusters, score))

plt.plot(K, Sum_of_squared_distances, 'gx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()

kmeans = KMeans(n_clusters=4)
kmeans.fit(songs_features)

# PCA to reduce our data to 2 dimensions for visualisation
y_kmeans = kmeans.predict(songs_features)
pca = PCA(n_components=2)
principal_components = pca.fit_transform(songs_features)

pc = pd.DataFrame(principal_components)
pc['label'] = y_kmeans
pc.columns = ['x', 'y', 'label']

# plot data with seaborn
cluster = sns.lmplot(data=pc, x='x', y='y', hue='label',
                     fit_reg=False, legend=True, legend_out=True)

pca.explained_variance_ratio_

# Dump components relations with features:
print(pd.DataFrame(pca.components_,
                   columns=songs_features.columns, index=['PC-1', 'PC-2']))

songs['label'] = y_kmeans

# shuffle dataset

songs = songs.sample(frac=1)
songs['label'].value_counts()

songs[songs['label'] == 0].tail(10)

songs[songs['label'] == 1].head(10)

songs[songs['label'] == 2].head(10)

songs[songs['label'] == 3].tail(50)

songs[songs['label'] == 3].hist()

songs[songs['label'] == 3].mean()


X = songs_features
y = y_kmeans

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)

rfc = RandomForestClassifier(n_estimators=100, criterion='gini')
rfc.fit(X_train, y_train)

# Predicting the Test set results
y_pred = rfc.predict(X_test)


def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax


# Confusion matrix
definitions = ['Study', 'Chill', 'Happy', 'Energetic']

plot_confusion_matrix(y_test, y_pred, classes=definitions,
                      title='Confusion matrix for Random Forest')

# View a list of the features and their importance scores
features = songs_features.columns
list(zip(songs_features[features], rfc.feature_importances_))

print(classification_report(y_test, y_pred, target_names=definitions)+'forest')
